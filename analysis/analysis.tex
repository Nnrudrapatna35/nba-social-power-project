\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Data Analysis},
            pdfauthor={Pipe It Up!: Nagaprasad Rudrapatna, Karen Deng, Jackson Muraika, Anna Zolotor},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Data Analysis}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Pipe It Up!: Nagaprasad Rudrapatna, Karen Deng, Jackson Muraika, Anna
Zolotor}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2020-04-17}


\begin{document}
\maketitle

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(broom)}
\KeywordTok{library}\NormalTok{(stringr)}
\KeywordTok{library}\NormalTok{(knitr)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(gridExtra)}
\KeywordTok{library}\NormalTok{(leaps)}
\KeywordTok{library}\NormalTok{(rms)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"../data/nba.csv"}\NormalTok{)}

\NormalTok{nba_}\DecValTok{2016}\NormalTok{_}\DecValTok{2017}\NormalTok{_}\DecValTok{100}\NormalTok{ <-}\StringTok{ }\NormalTok{nba_social_power}

\NormalTok{nba_social_power_mod <-}\StringTok{ }\NormalTok{nba_social_power }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(TWITTER_HANDLE }\OperatorTok{!=}\StringTok{ "0"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(PLAYER_NAME, }
\NormalTok{         TEAM_ABBREVIATION,}
\NormalTok{         AGE,}
\NormalTok{         W_PCT,}
\NormalTok{         OFF_RATING,}
\NormalTok{         DEF_RATING,}
\NormalTok{         NET_RATING,}
\NormalTok{         AST_RATIO,}
\NormalTok{         REB_PCT,}
\NormalTok{         USG_PCT,}
\NormalTok{         PIE,}
\NormalTok{         SALARY_MILLIONS,}
\NormalTok{         ACTIVE_TWITTER_LAST_YEAR,}
\NormalTok{         TWITTER_FOLLOWER_COUNT_MILLIONS,}
\NormalTok{         PTS) }
\end{Highlighting}
\end{Shaded}

\hypertarget{research-question-and-objective}{%
\subsubsection{Research Question and
Objective}\label{research-question-and-objective}}

The research question explored in this analysis is:
\texttt{Is\ there\ a\ relationship\ between\ measures\ of\ athletic\ success\ (win\ percentage,\ offensive\ and\ defensive\ ratings,\ etc.)\ and\ the\ internet\ “popularity”\ of\ NBA\ athletes,\ measured\ in\ the\ number\ of\ Twitter\ followers?}

The objective of this analysis is to predict Twitter follower counts of
NBA players using measures of athletic success.

\hypertarget{the-data}{%
\subsubsection{The Data}\label{the-data}}

The dataset we use in this analysis includes on-court performance data
for NBA players in the 2016-2017 season, along with their salaries and
Twitter engagement. The dataset is from Kaggle and references ESPN,
Basketball-Reference, Twitter, Five-ThirtyEight, and Wikipedia as data
sources. Because we are examining the relationship between player stats
and the number of Twitter followers, we filtered for players who had an
active Twitter account, by filtering for values where
\texttt{TWITTER\_HANDLE} is not ``NA'' (0). After filtering, we have 95
observations.

The response variable is \texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS},
which measures players' Twitter follower counts at the time the data was
collected.

\hypertarget{exploratory-data-analysis}{%
\subsubsection{Exploratory Data
Analysis}\label{exploratory-data-analysis}}

Although thorough and extensive EDA was done, this part of the analysis
only contains portions of the EDA deemed to be important. All additional
EDA can be found in the additional analysis section.

\hypertarget{univariate}{%
\paragraph{Univariate}\label{univariate}}

Complete univariate EDA was done and can be found in additional
analysis. Only the distributions of player salaries and twitter follower
counts were noticeably non-normal and non-symmetrical, thus giving us
important information about the data that needs to be kept in mind for
our model,are shown here.

Here, we'll look into players' salaries, in millions of dollars:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod,}
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ SALARY_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Player Salaries, in Millions of Dollars"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Player Salaries"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-1-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(SALARY_MILLIONS),}
            \DataTypeTok{min=} \KeywordTok{min}\NormalTok{(SALARY_MILLIONS),}
            \DataTypeTok{Q1 =} \KeywordTok{quantile}\NormalTok{(SALARY_MILLIONS, }\FloatTok{.25}\NormalTok{),}
            \DataTypeTok{median =} \KeywordTok{median}\NormalTok{(SALARY_MILLIONS),}
            \DataTypeTok{Q3 =} \KeywordTok{quantile}\NormalTok{(SALARY_MILLIONS, }\FloatTok{.75}\NormalTok{),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(SALARY_MILLIONS))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
##    mean   min    Q1 median    Q3   max
##   <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1  11.3  0.31  2.47   11.3  18.5  31.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(SALARY_MILLIONS)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(PLAYER_NAME, SALARY_MILLIONS) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##    PLAYER_NAME       SALARY_MILLIONS
##    <chr>                       <dbl>
##  1 LeBron James                 31.0
##  2 Russell Westbrook            26.5
##  3 Kevin Durant                 26.5
##  4 Mike Conley                  26.5
##  5 DeMar DeRozan                26.5
##  6 Al Horford                   26.5
##  7 James Harden                 26.5
##  8 Dirk Nowitzki                25  
##  9 Carmelo Anthony              24.6
## 10 Damian Lillard               24.3
\end{verbatim}

As we can see from the histogram, the distribution of salaries is
somewhat right-skewed, with most of the players making less than 20
million dollars a year. The mean salary is 11.3 million dollars a year.
The player who earns the most, at 30.96 million dollars per year, is
LeBron James (LeBron could be an influential point, so we will revisit
this after the model selection phase). On the other hand, Russell
Westbrook, Kevin Durant, Mike Conley, DeMar DeRozan, and Al Horford each
earn 26.54 million dollars per year.

Here, we'll look into the response variable,
\texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod,}
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{2}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Twitter Followers, in Millions"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Twitter Follower Counts"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS),}
            \DataTypeTok{min=} \KeywordTok{min}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS),}
            \DataTypeTok{Q1 =} \KeywordTok{quantile}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS, }\FloatTok{.25}\NormalTok{),}
            \DataTypeTok{median =}   \KeywordTok{median}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS),}
            \DataTypeTok{Q3 =} \KeywordTok{quantile}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS, }\FloatTok{.75}\NormalTok{),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
##    mean   min     Q1 median    Q3   max
##   <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl>
## 1  1.60 0.002 0.0595  0.246 0.912    37
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 15
##   PLAYER_NAME TEAM_ABBREVIATI~   AGE W_PCT OFF_RATING DEF_RATING NET_RATING
##   <chr>       <chr>            <int> <dbl>      <dbl>      <dbl>      <dbl>
## 1 LeBron Jam~ CLE                 32 0.689       115.       107.        7.7
## 2 Kevin Dura~ GSW                 28 0.823       117.       101.       16  
## # ... with 8 more variables: AST_RATIO <dbl>, REB_PCT <dbl>,
## #   USG_PCT <dbl>, PIE <dbl>, SALARY_MILLIONS <dbl>,
## #   ACTIVE_TWITTER_LAST_YEAR <int>, TWITTER_FOLLOWER_COUNT_MILLIONS <dbl>,
## #   PTS <dbl>
\end{verbatim}

From the histogram, we can see that the distribution of Twitter follower
counts is extremely right-skewed. The number of Twitter followers ranges
from .002 million to 37 million, with a mean of 1.6 million and a median
of.246 million. There are two obvious outliers: Kevin Durant, with 16.2
million followers, and LeBron James, with 37 million followers.

\hypertarget{bivariate}{%
\paragraph{Bivariate}\label{bivariate}}

Next, we will do bivariate EDA, looking into the relationships of some
of the predictor variables with the response variables. We won't do
bivariate EDA on player name, Twitter handle, age, team abbreviation, or
whether the players were active on Twitter last year, instead focusing
on terms we believe may play a more nuanced / important role in
predicting Twitter followers. Complete bivariate EDA is in additional
analysis; here, only those variables with evident relationships to the
response are included.

First, we'll look for a relationship between win percent and Twitter
followers in millions:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ W_PCT, }\DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Relationship Between Win Percent and Twitter Follower Count"}\NormalTok{, }
       \DataTypeTok{x =} \StringTok{"Win Percent"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-3-1.pdf}

From the above plot, we can see that win percent and Twitter follower
count may have a very weak positive orrelations. The players with
significantly higher-than-average Twitter follower counts tend to have
higher win percentages; however, this relationship is very weak.

Next, we'll look at the relationship between net rating, which combines
offensive and defensive rating, and Twitter follower count:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ NET_RATING, }\DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Relationship Between Net Rating and Twitter Follower Count"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Net Rating"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-4-1.pdf}

Similarly to win percent, Twitter follower count and net rating seem to
have a very weak positive relationship. The players with the highest net
ratings more often have higher-than-average Twitter follower counts, and
more players with positive net ratings have high Twitter follower counts
than those with negative net ratings.

Next, we'll examine whether there is a relationship between usage
percentage and Twitter follower count:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(nba_social_power_mod,}
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ USG_PCT,}
           \DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Relationship Between Usage Percentage and Twitter Follower Count"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Usage Percentage"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-5-1.pdf}

There appears to be a very weak positive correlation between usage
percentage and Twitter follower count; players with a high usage
percentage tend to have more Twitter followers, on average, than those
with a lower usage percentage.

Next, we'll examine whether there is a relationship between player
impact factor and Twitter follower count:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(nba_social_power_mod, }
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ PIE, }\DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Relationship Between Player Impact Factor and Twitter Follower Count"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Player Impact Factor"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-6-1.pdf}

There appears to be a somewhat positive correlation between player
impact factor and Twitter follower count; players with a high player
impact factor tend to have more Twitter followers, on average, than
those with a lower player impact factor.

Now, we'll look for a relationship between average points scored per
game and Twitter follower count:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(nba_social_power_mod,}
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ PTS, }\DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Relationship Between Avg. Points Scored and Twitter Follower Count"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Avg. Points Scored"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-7-1.pdf}

There appears to be a weak positive correlation between average points
scored and Twitter follower count; players with higher avg. points
scored tend to have more Twitter followers than those with lower avg.
points scored.

Finally, we'll look for a relationship between player salaries and
points scored:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ SALARY_MILLIONS, }\DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Relationship Between Player Salaries and Twitter Follower Count"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Salary, in Millions of Dollars"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-8-1.pdf}

There appears to be a positive correlation between salary and Twitter
follower count; the players with higher salaries tend to have higher
Twitter follower counts.

In sum, there appear to be weak to moderate positive correlations
between Twitter follower count and win percentage, net rating, usage
percentage, player impact factor, avg. points per game, and player
salaries; there is no obvious relationship between Twitter follower
count and assist-to-turnover ratio or rebound percentage.

\hypertarget{multivariate-data-analysis}{%
\subsubsection{Multivariate Data
Analysis}\label{multivariate-data-analysis}}

Now, we'll do some multivariate analysis. In this section, we are
looking for predictor variables that may affect the way other predictor
variables relate to the response variable.

First, we'll look to see if points scored affects the way player impact
factor (PIE) relates to Twitter follower count:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod1 <-}\StringTok{ }\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{PTS_CAT =} \KeywordTok{case_when}\NormalTok{(}
\NormalTok{    PTS }\OperatorTok{<=}\StringTok{ }\DecValTok{15} \OperatorTok{~}\StringTok{ "0-15"}\NormalTok{ , }
\NormalTok{    PTS }\OperatorTok{>}\StringTok{ }\DecValTok{15} \OperatorTok{~}\StringTok{ "more than 15"}
\NormalTok{  ))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod1,}
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ PIE, }
           \DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS,}
           \DataTypeTok{color =}\NormalTok{ PTS_CAT)) }\OperatorTok{+}
\StringTok{         }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Player Impact Factor"}\NormalTok{,}
       \DataTypeTok{y=} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{, }
       \DataTypeTok{color =} \StringTok{"Avg. Points Scored per Game"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Relationship Between Pts Scored, Twitter Followers, and Player Impact Factor"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-10-1.pdf}

As we can see from the above color-coded boxplot, many of the players
with the most points scored have higher player impact factors, and
player impact factor values have a weak positive correlation with the
Twitter follower count. This could be an opportunity for an interaction
term.

Next, we'll try to determine whether win percentage affects the way
salary relates to the Twitter follower count:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod1 <-}\StringTok{ }\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{W_PCT_CAT =} \KeywordTok{case_when}\NormalTok{(}
\NormalTok{    W_PCT }\OperatorTok{<=}\StringTok{ }\FloatTok{.5} \OperatorTok{~}\StringTok{ "less than half"}\NormalTok{ , }
\NormalTok{    W_PCT }\OperatorTok{>}\StringTok{ }\FloatTok{.5} \OperatorTok{~}\StringTok{ "more than half"}
\NormalTok{  ))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod1, }
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ SALARY_MILLIONS, }
           \DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS,}
           \DataTypeTok{color =}\NormalTok{ W_PCT_CAT)) }\OperatorTok{+}
\StringTok{         }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Salary, in Millions"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{, }
       \DataTypeTok{color =} \StringTok{"Proportion of Games Won"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Relationship Between Win Percentage,}
\StringTok{       Twitter Followers, and Salary"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-12-1.pdf}

As we can see from the scatterplot, players with higher win percentages
tend to be paid more, and high salary has a weak positive correlation
with the Twitter follower count. This could also be an opportunity for
an interaction term.

\hypertarget{adjustments-mean-centering}{%
\subsubsection{Adjustments
(Mean-Centering)}\label{adjustments-mean-centering}}

Before we proceed with the analysis, we will mean-center the
quantitative variables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod <-}\StringTok{ }\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{ageCent =}\NormalTok{ AGE }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(AGE),}
         \DataTypeTok{ast_ratioCent =}\NormalTok{ AST_RATIO }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(AST_RATIO),}
         \DataTypeTok{off_ratingCent =}\NormalTok{ OFF_RATING }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(OFF_RATING),}
         \DataTypeTok{def_ratingCent =}\NormalTok{ DEF_RATING }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(DEF_RATING),}
         \DataTypeTok{net_ratingCent =}\NormalTok{ NET_RATING }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(NET_RATING),}
         \DataTypeTok{PIECent =}\NormalTok{ PIE }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(PIE),}
         \DataTypeTok{reb_pctCent =}\NormalTok{ REB_PCT }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(REB_PCT),}
         \DataTypeTok{usg_pctCent =}\NormalTok{ USG_PCT }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(USG_PCT),}
         \DataTypeTok{salary_millionsCent =}\NormalTok{ SALARY_MILLIONS }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(SALARY_MILLIONS),}
         \DataTypeTok{w_pctCent =}\NormalTok{ W_PCT }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(W_PCT),}
         \DataTypeTok{ptsCent =}\NormalTok{ PTS }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(PTS))}
\end{Highlighting}
\end{Shaded}

\hypertarget{modeling-approach}{%
\subsubsection{Modeling Approach}\label{modeling-approach}}

As our response, \texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS}, is a
continuous numerical variable, we will use a multiple linear regression
model (obviously, we plan to include two or more predictors, so simple
linear regression would not apply!).

In regard to model selection, we will begin by fitting a mutiple linear
regression model with main effects, as well as interaction effects. We
are considering \texttt{salary\_millionsCent} * \texttt{w\_pctCent} and
\texttt{PIECent} * \texttt{ptsCent} as potential interaction terms for
our model since multivariate EDA highlighted strong positive
relationships between win percentage and player salaries and points
scored and PIE (player impact factor).

Next, we will perform two iterations of backward selection on the first
model: (i) using AIC as the selection criterion and (ii) using adjusted
R-squared as the selection criterion. We decided against trying BIC as
the selection criterion because we would prefer more terms in the final
model as our objective is to predict the Twitter follower counts of NBA
players using measures of athletic success (and predictions are
generally more accurate with more relevant predictor variables).

After completing the two iterations of backward selection, we will
compare the resulting models and see whether certain terms are removed
in both (which would suggest those terms are not statistically
significant).

After obtaining a final model, we will determine whether prominent
athletes (e.g.~LeBron James) are influential points by looking at
standardized residuals, leverage, and Cook's Distance (this is important
since our objective is to design a model with the best predictive
accuracy). We will then learn the impact of including versus excluding
prominent athletes in our model. We choose to analyze this at the end of
the model selection phase because prominent athletes are also included
in the population we want to understand when fitting the multiple linear
regression model.

\hypertarget{model-1}{%
\subsubsection{Model 1}\label{model-1}}

We will simply fit a model with eleven main effect
terms--\texttt{ageCent}, \texttt{ast\_ratioCent}
\texttt{off\_ratingCent}, \texttt{def\_ratingCent}, \texttt{PIECent},
\texttt{reb\_pctCent}, \texttt{usg\_pctCent},
\texttt{salary\_millionsCent}, \texttt{w\_pctCent}, \texttt{ptsCent},
and \texttt{ACTIVE\_TWITTER\_LAST\_YEAR}--and two interaction terms
(\texttt{salary\_millionsCent} * \texttt{w\_pctCent} and
\texttt{PIECent} * \texttt{ptsCent}). We decided to use
\texttt{off\_ratingCent} and \texttt{def\_ratingCent} as opposed to
\texttt{net\_ratingCent} because the two individual components
potentially provide more important information in predicting the number
of Twitter followers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS }\OperatorTok{~}\StringTok{ }\NormalTok{ageCent }\OperatorTok{+}
\StringTok{           }\NormalTok{ast_ratioCent }\OperatorTok{+}
\StringTok{           }\NormalTok{off_ratingCent }\OperatorTok{+}
\StringTok{           }\NormalTok{def_ratingCent }\OperatorTok{+}
\StringTok{           }\NormalTok{PIECent }\OperatorTok{+}
\StringTok{           }\NormalTok{reb_pctCent }\OperatorTok{+}
\StringTok{           }\NormalTok{usg_pctCent }\OperatorTok{+}
\StringTok{           }\NormalTok{salary_millionsCent }\OperatorTok{+}
\StringTok{           }\NormalTok{w_pctCent }\OperatorTok{+}
\StringTok{           }\NormalTok{ptsCent }\OperatorTok{+}
\StringTok{           }\NormalTok{ACTIVE_TWITTER_LAST_YEAR }\OperatorTok{+}
\StringTok{           }\NormalTok{salary_millionsCent }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent }\OperatorTok{+}
\StringTok{           }\NormalTok{PIECent }\OperatorTok{*}\StringTok{ }\NormalTok{ptsCent,}
         \DataTypeTok{data =}\NormalTok{ nba_social_power_mod)}
\KeywordTok{tidy}\NormalTok{(m1, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & -2.386 & 2.744 & -0.869 & 0.387 & -7.845 &
3.074\tabularnewline
ageCent & 0.262 & 0.123 & 2.131 & 0.036 & 0.017 & 0.507\tabularnewline
ast\_ratioCent & 0.017 & 0.064 & 0.269 & 0.788 & -0.109 &
0.144\tabularnewline
off\_ratingCent & 0.026 & 0.106 & 0.247 & 0.805 & -0.185 &
0.237\tabularnewline
def\_ratingCent & 0.086 & 0.118 & 0.732 & 0.467 & -0.149 &
0.321\tabularnewline
PIECent & 13.104 & 27.617 & 0.474 & 0.636 & -41.846 &
68.053\tabularnewline
reb\_pctCent & 7.689 & 12.120 & 0.634 & 0.528 & -16.426 &
31.803\tabularnewline
usg\_pctCent & 0.052 & 14.017 & 0.004 & 0.997 & -27.838 &
27.942\tabularnewline
salary\_millionsCent & 0.086 & 0.070 & 1.240 & 0.219 & -0.052 &
0.225\tabularnewline
w\_pctCent & 7.095 & 3.834 & 1.850 & 0.068 & -0.534 &
14.725\tabularnewline
ptsCent & 0.063 & 0.132 & 0.481 & 0.632 & -0.199 & 0.325\tabularnewline
ACTIVE\_TWITTER\_LAST\_YEAR & 3.523 & 2.758 & 1.278 & 0.205 & -1.964 &
9.011\tabularnewline
salary\_millionsCent:w\_pctCent & 0.999 & 0.344 & 2.901 & 0.005 & 0.314
& 1.684\tabularnewline
PIECent:ptsCent & 1.293 & 2.293 & 0.564 & 0.574 & -3.269 &
5.855\tabularnewline
\bottomrule
\end{longtable}

Based on the output, the equation of the linear model is:
\texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS}-hat = -2.386 + 0.262 *
\texttt{ageCent} + 0.017 * \texttt{ast\_ratioCent} + 0.026 *
\texttt{off\_ratingCent} + 0.086 * \texttt{def\_ratingCent} + 13.104 *
\texttt{PIECent} + 7.689 * \texttt{reb\_pctCent} + 0.052 *
\texttt{usg\_pctCent} + 0.086 * \texttt{salary\_millionsCent} + 7.095 *
\texttt{w\_pctCent} + 0.063 * \texttt{ptsCent} + 3.523 *
\texttt{ACTIVE\_TWITTER\_LAST\_YEAR1} + 0.999 *
\texttt{salary\_millionsCent\ *\ w\_pct\_Cent} + 1.293 *
\texttt{PIECent\ *\ ptsCent}.

\hypertarget{backward-selection-iteration-1}{%
\subsubsection{Backward Selection (Iteration
1)}\label{backward-selection-iteration-1}}

We will now perform the first iteration of backward selection using AIC
as the selection criterion:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1_aic <-}\StringTok{ }\KeywordTok{step}\NormalTok{(m1, }\DataTypeTok{direction =} \StringTok{"backward"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Start:  AIC=265.14
## TWITTER_FOLLOWER_COUNT_MILLIONS ~ ageCent + ast_ratioCent + off_ratingCent + 
##     def_ratingCent + PIECent + reb_pctCent + usg_pctCent + salary_millionsCent + 
##     w_pctCent + ptsCent + ACTIVE_TWITTER_LAST_YEAR + salary_millionsCent * 
##     w_pctCent + PIECent * ptsCent
## 
##                                 Df Sum of Sq    RSS    AIC
## - usg_pctCent                    1     0.000 1153.0 263.14
## - off_ratingCent                 1     0.869 1153.8 263.21
## - ast_ratioCent                  1     1.033 1154.0 263.23
## - PIECent:ptsCent                1     4.525 1157.5 263.51
## - reb_pctCent                    1     5.729 1158.7 263.61
## - def_ratingCent                 1     7.619 1160.6 263.77
## - ACTIVE_TWITTER_LAST_YEAR       1    23.232 1176.2 265.04
## <none>                                       1153.0 265.14
## - ageCent                        1    64.667 1217.6 268.32
## - salary_millionsCent:w_pctCent  1   119.780 1272.7 272.53
## 
## Step:  AIC=263.14
## TWITTER_FOLLOWER_COUNT_MILLIONS ~ ageCent + ast_ratioCent + off_ratingCent + 
##     def_ratingCent + PIECent + reb_pctCent + salary_millionsCent + 
##     w_pctCent + ptsCent + ACTIVE_TWITTER_LAST_YEAR + salary_millionsCent:w_pctCent + 
##     PIECent:ptsCent
## 
##                                 Df Sum of Sq    RSS    AIC
## - off_ratingCent                 1     0.879 1153.8 261.21
## - ast_ratioCent                  1     1.119 1154.1 261.23
## - PIECent:ptsCent                1     4.673 1157.6 261.52
## - reb_pctCent                    1     6.349 1159.3 261.66
## - def_ratingCent                 1     7.812 1160.8 261.78
## - ACTIVE_TWITTER_LAST_YEAR       1    23.398 1176.4 263.05
## <none>                                       1153.0 263.14
## - ageCent                        1    65.008 1218.0 266.35
## - salary_millionsCent:w_pctCent  1   120.208 1273.2 270.56
## 
## Step:  AIC=261.21
## TWITTER_FOLLOWER_COUNT_MILLIONS ~ ageCent + ast_ratioCent + def_ratingCent + 
##     PIECent + reb_pctCent + salary_millionsCent + w_pctCent + 
##     ptsCent + ACTIVE_TWITTER_LAST_YEAR + salary_millionsCent:w_pctCent + 
##     PIECent:ptsCent
## 
##                                 Df Sum of Sq    RSS    AIC
## - ast_ratioCent                  1     1.551 1155.4 259.34
## - PIECent:ptsCent                1     3.809 1157.7 259.53
## - reb_pctCent                    1     6.572 1160.4 259.75
## - def_ratingCent                 1    10.226 1164.1 260.05
## - ACTIVE_TWITTER_LAST_YEAR       1    23.162 1177.0 261.10
## <none>                                       1153.8 261.21
## - ageCent                        1    64.179 1218.0 264.36
## - salary_millionsCent:w_pctCent  1   144.592 1298.4 270.43
## 
## Step:  AIC=259.34
## TWITTER_FOLLOWER_COUNT_MILLIONS ~ ageCent + def_ratingCent + 
##     PIECent + reb_pctCent + salary_millionsCent + w_pctCent + 
##     ptsCent + ACTIVE_TWITTER_LAST_YEAR + salary_millionsCent:w_pctCent + 
##     PIECent:ptsCent
## 
##                                 Df Sum of Sq    RSS    AIC
## - PIECent:ptsCent                1     5.074 1160.5 257.76
## - reb_pctCent                    1     5.330 1160.7 257.78
## - def_ratingCent                 1    10.283 1165.7 258.18
## - ACTIVE_TWITTER_LAST_YEAR       1    24.144 1179.5 259.31
## <none>                                       1155.4 259.34
## - ageCent                        1    64.470 1219.9 262.50
## - salary_millionsCent:w_pctCent  1   156.501 1311.9 269.41
## 
## Step:  AIC=257.76
## TWITTER_FOLLOWER_COUNT_MILLIONS ~ ageCent + def_ratingCent + 
##     PIECent + reb_pctCent + salary_millionsCent + w_pctCent + 
##     ptsCent + ACTIVE_TWITTER_LAST_YEAR + salary_millionsCent:w_pctCent
## 
##                                 Df Sum of Sq    RSS    AIC
## - ptsCent                        1     6.132 1166.6 256.26
## - reb_pctCent                    1     8.021 1168.5 256.41
## - def_ratingCent                 1    10.161 1170.6 256.58
## - PIECent                        1    12.392 1172.9 256.77
## - ACTIVE_TWITTER_LAST_YEAR       1    23.951 1184.4 257.70
## <none>                                       1160.5 257.76
## - ageCent                        1    70.150 1230.6 261.33
## - salary_millionsCent:w_pctCent  1   164.153 1324.6 268.32
## 
## Step:  AIC=256.26
## TWITTER_FOLLOWER_COUNT_MILLIONS ~ ageCent + def_ratingCent + 
##     PIECent + reb_pctCent + salary_millionsCent + w_pctCent + 
##     ACTIVE_TWITTER_LAST_YEAR + salary_millionsCent:w_pctCent
## 
##                                 Df Sum of Sq    RSS    AIC
## - reb_pctCent                    1     3.143 1169.7 254.51
## - def_ratingCent                 1    11.861 1178.5 255.22
## <none>                                       1166.6 256.26
## - ACTIVE_TWITTER_LAST_YEAR       1    25.646 1192.2 256.32
## - PIECent                        1    31.477 1198.1 256.79
## - ageCent                        1    64.560 1231.2 259.37
## - salary_millionsCent:w_pctCent  1   158.085 1324.7 266.33
## 
## Step:  AIC=254.51
## TWITTER_FOLLOWER_COUNT_MILLIONS ~ ageCent + def_ratingCent + 
##     PIECent + salary_millionsCent + w_pctCent + ACTIVE_TWITTER_LAST_YEAR + 
##     salary_millionsCent:w_pctCent
## 
##                                 Df Sum of Sq    RSS    AIC
## - def_ratingCent                 1    11.079 1180.8 253.41
## <none>                                       1169.7 254.51
## - ACTIVE_TWITTER_LAST_YEAR       1    25.350 1195.1 254.55
## - PIECent                        1    36.705 1206.5 255.45
## - ageCent                        1    62.548 1232.3 257.46
## - salary_millionsCent:w_pctCent  1   155.368 1325.1 264.36
## 
## Step:  AIC=253.41
## TWITTER_FOLLOWER_COUNT_MILLIONS ~ ageCent + PIECent + salary_millionsCent + 
##     w_pctCent + ACTIVE_TWITTER_LAST_YEAR + salary_millionsCent:w_pctCent
## 
##                                 Df Sum of Sq    RSS    AIC
## - ACTIVE_TWITTER_LAST_YEAR       1    25.051 1205.9 253.40
## <none>                                       1180.8 253.41
## - PIECent                        1    32.005 1212.8 253.95
## - ageCent                        1    54.622 1235.4 255.70
## - salary_millionsCent:w_pctCent  1   162.024 1342.8 263.62
## 
## Step:  AIC=253.4
## TWITTER_FOLLOWER_COUNT_MILLIONS ~ ageCent + PIECent + salary_millionsCent + 
##     w_pctCent + salary_millionsCent:w_pctCent
## 
##                                 Df Sum of Sq    RSS    AIC
## <none>                                       1205.9 253.40
## - PIECent                        1    29.646 1235.5 253.71
## - ageCent                        1    60.024 1265.9 256.02
## - salary_millionsCent:w_pctCent  1   158.457 1364.3 263.13
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(m1_aic, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & 1.175 & 0.397 & 2.957 & 0.004 & 0.386 &
1.964\tabularnewline
ageCent & 0.225 & 0.107 & 2.105 & 0.038 & 0.013 & 0.437\tabularnewline
PIECent & 27.461 & 18.565 & 1.479 & 0.143 & -9.427 &
64.349\tabularnewline
salary\_millionsCent & 0.111 & 0.051 & 2.158 & 0.034 & 0.009 &
0.213\tabularnewline
w\_pctCent & 6.294 & 2.761 & 2.280 & 0.025 & 0.808 &
11.780\tabularnewline
salary\_millionsCent:w\_pctCent & 1.019 & 0.298 & 3.420 & 0.001 & 0.427
& 1.611\tabularnewline
\bottomrule
\end{longtable}

Based on the output displayed above from the first iteration of backward
selection (using AIC as the selection criterion), seven main effect
terms (\texttt{ast\_ratioCent} \texttt{off\_ratingCent},
\texttt{def\_ratingCent}, \texttt{reb\_pctCent}, \texttt{usg\_pctCent},
\texttt{ptsCent}, and \texttt{ACTIVE\_TWITTER\_LAST\_YEAR1}) and one
interaction term (\texttt{PIECent} * \texttt{ptsCent}) were removed.

Hence, the equation of the selected linear model is:
\texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS}-hat = 1.175 + 0.225 *
\texttt{ageCent} + 27.461 * \texttt{PIECent} + 0.111 *
\texttt{salary\_millionsCent} + 6.294 * \texttt{w\_pctCent} + 1.019 *
\texttt{salary\_millionsCent\ *\ w\_pctCent}.

However, \texttt{PIECent}, which has the highest slope coefficient in
the linear model, has a high standard error and a high p-value (0.143).
Furthermore, the confidence interval for the slope coefficient is
extremely wide (-9.427 to 64.349), not to mention the fact that it
includes zero. So, we can reasonably infer \texttt{PIECent} may be a
particularly troublesome predictor in the model (especially since it
appears to not significantly affect the response,
\texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS}).

We will proceed with the second iteration of backward selection and will
revisit the issue of \texttt{PIECent} after viewing the selected linear
regression model based on adjusted R-squared.

\hypertarget{backward-selection-iteration-2}{%
\subsubsection{Backward Selection (Iteration
2)}\label{backward-selection-iteration-2}}

Next, we will perform the second iteration of backward selection using
adjusted R-squared as the selection criterion:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1_adjR <-}\StringTok{ }\KeywordTok{regsubsets}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS }\OperatorTok{~}\StringTok{ }\NormalTok{ageCent }\OperatorTok{+}
\StringTok{           }\NormalTok{ast_ratioCent }\OperatorTok{+}
\StringTok{           }\NormalTok{off_ratingCent }\OperatorTok{+}
\StringTok{           }\NormalTok{def_ratingCent }\OperatorTok{+}
\StringTok{           }\NormalTok{PIECent }\OperatorTok{+}
\StringTok{           }\NormalTok{reb_pctCent }\OperatorTok{+}
\StringTok{           }\NormalTok{usg_pctCent }\OperatorTok{+}
\StringTok{           }\NormalTok{salary_millionsCent }\OperatorTok{+}
\StringTok{           }\NormalTok{w_pctCent }\OperatorTok{+}
\StringTok{           }\NormalTok{ptsCent }\OperatorTok{+}
\StringTok{           }\NormalTok{ACTIVE_TWITTER_LAST_YEAR }\OperatorTok{+}
\StringTok{           }\NormalTok{salary_millionsCent }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent }\OperatorTok{+}
\StringTok{           }\NormalTok{PIECent }\OperatorTok{*}\StringTok{ }\NormalTok{ptsCent,}
         \DataTypeTok{data =}\NormalTok{ nba_social_power_mod,}
         \DataTypeTok{method =} \StringTok{"backward"}\NormalTok{)}

\NormalTok{select_summary <-}\StringTok{ }\KeywordTok{summary}\NormalTok{(m1_adjR)}
\KeywordTok{coef}\NormalTok{(m1_adjR, }\KeywordTok{which.max}\NormalTok{(select_summary}\OperatorTok{$}\NormalTok{adjr2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                   (Intercept)                       ageCent 
##                    -2.3794214                     0.2146898 
##                       PIECent           salary_millionsCent 
##                    28.5598883                     0.1148099 
##                     w_pctCent      ACTIVE_TWITTER_LAST_YEAR 
##                     6.6375685                     3.6257226 
## salary_millionsCent:w_pctCent 
##                     1.0306857
\end{verbatim}

Based on the output displayed above from the second iteration of
backward selection (using adjusted R-squared as the selection
criterion), six main effect terms (\texttt{ast\_ratioCent}
\texttt{off\_ratingCent}, \texttt{def\_ratingCent},
\texttt{reb\_pctCent}, \texttt{usg\_pctCent}, and \texttt{ptsCent}) and
one interaction term (\texttt{PIECent} * \texttt{ptsCent}) were removed.

Hence, the equation of the selected linear model is:
\texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS}-hat = -2.379 + 0.215 *
\texttt{ageCent} + 28.560 * \texttt{PIECent} + 0.115 *
\texttt{salary\_millionsCent} + 6.638 * \texttt{w\_pctCent} + 3.626 *
\texttt{ACTIVE\_TWITTER\_LAST\_YEAR1} + 1.031 *
\texttt{salary\_millionsCent\ *\ w\_pct\_Cent}.

\hypertarget{model-comparison-aic-vs.adjusted-r-squared}{%
\subsubsection{Model Comparison: AIC vs.~Adjusted
R-squared}\label{model-comparison-aic-vs.adjusted-r-squared}}

We notice that the model selected using adjusted R-squared as the
selection criterion includes an additional categorical term
(\texttt{ACTIVE\_TWITTER\_LAST\_YEAR1}) which was omitted in the model
selected based on the first iteration of backward selection (using AIC
as the selection criterion).

If we closely investigate the results of the \texttt{step()} function,
we can see that \texttt{ACTIVE\_TWITTER\_LAST\_YEAR} was the last
predictor removed during the first iteration of backward selection. In
fact, the difference in AIC between the final two steps is only
\texttt{253.41\ -\ 253.4\ =\ 0.01}.

This warrants further consideration:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1_modV1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS }\OperatorTok{~}\StringTok{ }\NormalTok{ageCent }\OperatorTok{+}
\StringTok{               }\NormalTok{salary_millionsCent }\OperatorTok{+}
\StringTok{               }\NormalTok{PIECent }\OperatorTok{+}
\StringTok{               }\NormalTok{w_pctCent }\OperatorTok{+}
\StringTok{               }\NormalTok{ACTIVE_TWITTER_LAST_YEAR }\OperatorTok{+}
\StringTok{               }\NormalTok{salary_millionsCent }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent,}
             \DataTypeTok{data =}\NormalTok{ nba_social_power_mod)}

\KeywordTok{tidy}\NormalTok{(m1_modV1, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & -2.379 & 2.631 & -0.904 & 0.368 & -7.608 &
2.850\tabularnewline
ageCent & 0.215 & 0.106 & 2.018 & 0.047 & 0.003 & 0.426\tabularnewline
salary\_millionsCent & 0.115 & 0.051 & 2.244 & 0.027 & 0.013 &
0.216\tabularnewline
PIECent & 28.560 & 18.493 & 1.544 & 0.126 & -8.190 &
65.310\tabularnewline
w\_pctCent & 6.638 & 2.759 & 2.406 & 0.018 & 1.155 &
12.120\tabularnewline
ACTIVE\_TWITTER\_LAST\_YEAR & 3.626 & 2.654 & 1.366 & 0.175 & -1.648 &
8.899\tabularnewline
salary\_millionsCent:w\_pctCent & 1.031 & 0.297 & 3.475 & 0.001 & 0.441
& 1.620\tabularnewline
\bottomrule
\end{longtable}

Based on the p-value associated with the slope coefficient for
\texttt{ACTIVE\_TWITTER\_LAST\_YEAR1} (0.175) and the confidence
interval associated with this coefficient (-1.648 to 8.899; includes
zero), it is clear that \texttt{ACTIVE\_TWITTER\_LAST\_YEAR} is not a
significant predictor of \texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS}.\\
Again, recalling our objective in this analysis--to predict Twitter
follower counts of NBA players--we choose to leave
\texttt{ACTIVE\_TWITTER\_LAST\_YEAR} out of the final model because,
although the information provided by this categorical variable may, at
first glance, appear relevant to the response,
\texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS} (which measures players'
total Twitter follower counts), the p-value and confidence interval
associated with this predictor's slope coefficient suggests otherwise.
When designing a model for predictive purposes, we are mostly interested
in variables which are strong predictors of the response. Hence, we
concur with the model selected by backward selection using AIC as the
selection criterion in regard to \texttt{ACTIVE\_TWITTER\_LAST\_YEAR}.

Now, as promised, we return to the issue of \texttt{PIECent}.
Unfortunately, both selected models included \texttt{PIECent}; thus, we
must decide whether to keep the variable in the model, or to ignore the
results from the two iterations of backward selection and remove it.

To answer this question, we will compare the AIC and adjusted R-squared
values for the model selected based on AIC as the selection criterion
(first iteration) and the same model except without \texttt{PIECent},
remembering that we have already excluded
\texttt{ACTIVE\_TWITTER\_LAST\_YEAR}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1_modV2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS }\OperatorTok{~}\StringTok{ }\NormalTok{ageCent }\OperatorTok{+}
\StringTok{               }\NormalTok{salary_millionsCent }\OperatorTok{+}
\StringTok{               }\NormalTok{PIECent }\OperatorTok{+}
\StringTok{               }\NormalTok{w_pctCent }\OperatorTok{+}
\StringTok{               }\NormalTok{salary_millionsCent }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent,}
             \DataTypeTok{data =}\NormalTok{ nba_social_power_mod)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1_modV3 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS }\OperatorTok{~}\StringTok{ }\NormalTok{ageCent }\OperatorTok{+}
\StringTok{                 }\NormalTok{salary_millionsCent }\OperatorTok{+}
\StringTok{                 }\NormalTok{w_pctCent }\OperatorTok{+}
\StringTok{                 }\NormalTok{salary_millionsCent }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent,}
               \DataTypeTok{data =}\NormalTok{ nba_social_power_mod)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glance}\NormalTok{(m1_modV2)}\OperatorTok{$}\NormalTok{AIC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 525.001
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glance}\NormalTok{(m1_modV2)}\OperatorTok{$}\NormalTok{adj.r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3141706
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glance}\NormalTok{(m1_modV3)}\OperatorTok{$}\NormalTok{AIC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 525.3083
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glance}\NormalTok{(m1_modV3)}\OperatorTok{$}\NormalTok{adj.r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3051171
\end{verbatim}

Based on the output of the \texttt{glance()} function, the AIC of the
model with \texttt{PIECent} is 525.001. Conversely, the AIC of the model
without \texttt{PIECent} is 525.3083.

Moreover, the adjusted R-squared value for the model with
\texttt{PIECent} is roughly 0.314, whereas the adjusted R-squared value
for the model without \texttt{PIECent} is about 0.305.

Therefore, the model with \texttt{PIECent} maximizes adjusted R-squared
and minimizes AIC. But our qualms with the large standard error, high
p-value, and wide confidence interval (including zero) cannot be
ignored, especially considering the purpose of our analysis--prediction.
Hence, as with \texttt{ACTIVE\_TWITTER\_LAST\_YEAR}, we will leave
\texttt{PIECent} out of the model because including a variable which is
not a strong predictor of the response will result in wider prediction
intervals.

Of course, this means the only measures of athletic success remaining in
the model are: mean-centered win percentage and (to a lesser degree due
to salary cap restrictions) player salaries. Nevertheless, we have
tailored our model selection phase towards our objective--predicting the
number of Twitter followers--and cannot be too upset since such a model
will yield relatively narrow prediction intervals.

Now, examining the current model:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(m1_modV3, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & 1.142 & 0.399 & 2.859 & 0.005 & 0.348 &
1.935\tabularnewline
ageCent & 0.192 & 0.105 & 1.829 & 0.071 & -0.017 & 0.401\tabularnewline
salary\_millionsCent & 0.137 & 0.048 & 2.844 & 0.006 & 0.041 &
0.234\tabularnewline
w\_pctCent & 7.131 & 2.720 & 2.622 & 0.010 & 1.727 &
12.535\tabularnewline
salary\_millionsCent:w\_pctCent & 1.099 & 0.295 & 3.729 & 0.000 & 0.514
& 1.685\tabularnewline
\bottomrule
\end{longtable}

But now we notice another problem: \texttt{ageCent} has a high p-value
(0.071) and a confidence interval including zero. Hence, we will also
remove \texttt{ageCent} using the same rationale as with
\texttt{ACTIVE\_TWITTER\_LAST\_YEAR} and \texttt{PIECent}.

\hypertarget{final-model}{%
\subsubsection{Final Model}\label{final-model}}

Thus, our final model is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m_final <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS }\OperatorTok{~}\StringTok{ }\NormalTok{salary_millionsCent }\OperatorTok{+}
\StringTok{                 }\NormalTok{w_pctCent }\OperatorTok{+}
\StringTok{                 }\NormalTok{salary_millionsCent }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent,}
               \DataTypeTok{data =}\NormalTok{ nba_social_power_mod)}

\KeywordTok{tidy}\NormalTok{(m_final, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & 1.184 & 0.404 & 2.933 & 0.004 & 0.382 &
1.986\tabularnewline
salary\_millionsCent & 0.163 & 0.047 & 3.479 & 0.001 & 0.070 &
0.256\tabularnewline
w\_pctCent & 7.761 & 2.733 & 2.840 & 0.006 & 2.334 &
13.189\tabularnewline
salary\_millionsCent:w\_pctCent & 0.997 & 0.293 & 3.401 & 0.001 & 0.415
& 1.579\tabularnewline
\bottomrule
\end{longtable}

The equation of the final model is:
\texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS}-hat = 1.184 + 0.163 *
\texttt{salary\_millionsCent} + 7.761 * \texttt{w\_pctCent} + 0.997 *
\texttt{salary\_millionsCent\ *\ w\_pct\_Cent}.

\hypertarget{impact-of-prominent-players}{%
\subsubsection{Impact of Prominent
Players}\label{impact-of-prominent-players}}

Lastly, before proceeding to discuss assumptions, we would like to
examine the impact of including versus excluding prominent athletes in
our model. Since he is widely regarded as one of the best NBA players of
all-time, we will use LeBron James as a case study for preliminary
analysis:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(SALARY_MILLIONS)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(PLAYER_NAME, SALARY_MILLIONS) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##    PLAYER_NAME       SALARY_MILLIONS
##    <chr>                       <dbl>
##  1 LeBron James                 31.0
##  2 Russell Westbrook            26.5
##  3 Kevin Durant                 26.5
##  4 Mike Conley                  26.5
##  5 DeMar DeRozan                26.5
##  6 Al Horford                   26.5
##  7 James Harden                 26.5
##  8 Dirk Nowitzki                25  
##  9 Carmelo Anthony              24.6
## 10 Damian Lillard               24.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(PLAYER_NAME, TWITTER_FOLLOWER_COUNT_MILLIONS) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##    PLAYER_NAME       TWITTER_FOLLOWER_COUNT_MILLIONS
##    <chr>                                       <dbl>
##  1 LeBron James                                37   
##  2 Kevin Durant                                16.2 
##  3 Stephen Curry                                9.56
##  4 Carmelo Anthony                              8.94
##  5 Dwyane Wade                                  7.01
##  6 Dwight Howard                                6.97
##  7 Chris Paul                                   6.4 
##  8 Pau Gasol                                    6.38
##  9 Russell Westbrook                            4.5 
## 10 James Harden                                 4.47
\end{verbatim}

Based on the tables above, it is seems like LeBron James is an outlier,
both in regard to his annual salary and Twitter follower count. So, we
will remove LeBron from the dataset and see how the model changes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod2 <-}\StringTok{ }\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(PLAYER_NAME }\OperatorTok{!=}\StringTok{ "LeBron James"}\NormalTok{)}

\KeywordTok{glimpse}\NormalTok{(nba_social_power_mod2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Observations: 94
## Variables: 26
## $ PLAYER_NAME                     <chr> "Russell Westbrook", "Demetriu...
## $ TEAM_ABBREVIATION               <chr> "OKC", "BOS", "NOP", "HOU", "G...
## $ AGE                             <int> 28, 22, 24, 27, 28, 32, 26, 22...
## $ W_PCT                           <dbl> 0.568, 0.200, 0.413, 0.667, 0....
## $ OFF_RATING                      <dbl> 107.9, 124.2, 104.2, 113.6, 11...
## $ DEF_RATING                      <dbl> 104.6, 117.8, 102.5, 107.3, 10...
## $ NET_RATING                      <dbl> 3.3, 6.3, 1.7, 6.3, 16.0, 14.9...
## $ AST_RATIO                       <dbl> 23.4, 31.1, 7.3, 27.6, 18.4, 3...
## $ REB_PCT                         <dbl> 0.167, 0.103, 0.170, 0.123, 0....
## $ USG_PCT                         <dbl> 0.408, 0.172, 0.326, 0.341, 0....
## $ PIE                             <dbl> 0.230, 0.194, 0.192, 0.190, 0....
## $ SALARY_MILLIONS                 <dbl> 26.54, 1.45, 22.12, 26.50, 26....
## $ ACTIVE_TWITTER_LAST_YEAR        <int> 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, ...
## $ TWITTER_FOLLOWER_COUNT_MILLIONS <dbl> 4.500, 0.049, 1.220, 4.470, 16...
## $ PTS                             <dbl> 31.6, 2.0, 28.0, 29.1, 25.1, 1...
## $ ageCent                         <dbl> 0.6105263, -5.3894737, -3.3894...
## $ ast_ratioCent                   <dbl> 6.274737, 13.974737, -9.825263...
## $ off_ratingCent                  <dbl> -0.009473684, 16.290526316, -3...
## $ def_ratingCent                  <dbl> -1.39368421, 11.80631579, -3.4...
## $ net_ratingCent                  <dbl> 1.3810526, 4.3810526, -0.21894...
## $ PIECent                         <dbl> 0.09073684, 0.05473684, 0.0527...
## $ reb_pctCent                     <dbl> 0.033778947, -0.030221053, 0.0...
## $ usg_pctCent                     <dbl> 0.170, -0.066, 0.088, 0.103, 0...
## $ salary_millionsCent             <dbl> 15.2351368, -9.8548632, 10.815...
## $ w_pctCent                       <dbl> 0.056589474, -0.311410526, -0....
## $ ptsCent                         <dbl> 16.3176842, -13.2823158, 12.71...
\end{verbatim}

Based on the \texttt{glimpse()} output, we can see LeBron has been
removed from the dataset (94 observations remaining).

Now, to assess the impact of his absence on the final model:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m_final_noLJ <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS }\OperatorTok{~}\StringTok{ }\NormalTok{salary_millionsCent }\OperatorTok{+}
\StringTok{                 }\NormalTok{w_pctCent }\OperatorTok{+}
\StringTok{                 }\NormalTok{salary_millionsCent }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent,}
               \DataTypeTok{data =}\NormalTok{ nba_social_power_mod2)}

\KeywordTok{tidy}\NormalTok{(m_final_noLJ, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & 1.087 & 0.229 & 4.742 & 0.000 & 0.632 &
1.543\tabularnewline
salary\_millionsCent & 0.109 & 0.027 & 4.035 & 0.000 & 0.055 &
0.162\tabularnewline
w\_pctCent & 4.609 & 1.568 & 2.940 & 0.004 & 1.495 &
7.724\tabularnewline
salary\_millionsCent:w\_pctCent & 0.431 & 0.171 & 2.513 & 0.014 & 0.090
& 0.771\tabularnewline
\bottomrule
\end{longtable}

The equation of the final model without LeBron James is:
\texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS}-hat = 1.087 + 0.109 *
\texttt{salary\_millionsCent} + 4.609 * \texttt{w\_pctCent} + 0.431 *
\texttt{salary\_millionsCent\ *\ w\_pct\_Cent}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(W_PCT)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(PLAYER_NAME, W_PCT) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 2
##    PLAYER_NAME       W_PCT
##    <chr>             <dbl>
##  1 David West        0.824
##  2 Kevin Durant      0.823
##  3 Stephen Curry     0.823
##  4 Draymond Green    0.816
##  5 JaVale McGee      0.805
##  6 Pau Gasol         0.734
##  7 David Lee         0.734
##  8 Kawhi Leonard     0.73 
##  9 Dewayne Dedmon    0.724
## 10 LaMarcus Aldridge 0.722
## 11 Chris Paul        0.705
## 12 LeBron James      0.689
## 13 Clint Capela      0.677
## 14 Al Horford        0.676
## 15 George Hill       0.673
\end{verbatim}

Comparing the two equations, we notice a relatively sizable discrepancy
in the slope coefficient of \texttt{w\_pctCent}. This makes sense since
LeBron has the twelfth-highest win percentage in the league (0.689), so
eliminating him from the dataset dramatically affects the average win
percentage (as well as the spread, or standard deviation).

More generally, to determine whether prominent athletes are influential
points, we will look at standardized residuals, leverage, and Cook's
Distance:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{augmented_data <-}\StringTok{ }\KeywordTok{augment}\NormalTok{(m_final)}

\NormalTok{augmented_data <-}\StringTok{ }\NormalTok{augmented_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{obs_num =} \KeywordTok{row_number}\NormalTok{())}

\NormalTok{threshold <-}\StringTok{ }\NormalTok{((}\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{3} \OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{)) }\OperatorTok{/}\StringTok{ }\DecValTok{95}\NormalTok{) }

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ augmented_data, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ obs_num, }\DataTypeTok{y =}\NormalTok{ .hat)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =}\NormalTok{ threshold, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Observation Number"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Leverage Value"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Observation Number vs. Leverage Value"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/leverage-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{augmented_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(.hat }\OperatorTok{>}\StringTok{ }\NormalTok{threshold) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(obs_num, .hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 7 x 2
##   obs_num   .hat
##     <int>  <dbl>
## 1       5 0.211 
## 2       6 0.118 
## 3      38 0.184 
## 4      63 0.0973
## 5      69 0.104 
## 6      75 0.187 
## 7      78 0.104
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_leverage <-}\StringTok{ }\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{obs_num =} \KeywordTok{row_number}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{5} \OperatorTok{|}\StringTok{ }\NormalTok{obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{6} \OperatorTok{|}\StringTok{ }\NormalTok{obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{38} \OperatorTok{|}
\StringTok{           }\NormalTok{obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{63} \OperatorTok{|}\StringTok{ }\NormalTok{obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{69} \OperatorTok{|}\StringTok{ }\NormalTok{obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{75} \OperatorTok{|}
\StringTok{           }\NormalTok{obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{78}\NormalTok{)}

\NormalTok{nba_leverage }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(obs_num, PLAYER_NAME)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 7 x 2
##   obs_num PLAYER_NAME    
##     <int> <chr>          
## 1       5 Kevin Durant   
## 2       6 LeBron James   
## 3      38 Josh Huestis   
## 4      63 JaVale McGee   
## 5      69 David West     
## 6      75 Jarnell Stokes 
## 7      78 Carmelo Anthony
\end{verbatim}

Based on the threshold (\texttt{2(p\ +\ 1)\ /\ n}), Kevin Durant, LeBron
James, Josh Huestis, JaVale McGee, David West, Jarnell Stokes, and
Carmelo Anthony are considered high leverage players (and hence
potential influential points).

Now, to identify outliers within these candidates, we will look at the
standardized residuals:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ augmented_data, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ .fitted, }\DataTypeTok{y =}\NormalTok{ .std.resid)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{2}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{-2}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Predicted Number of Twitter Followers"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Standardized Residuals"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Standardized Residuals vs. Predicted Twitter Follower Counts"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/standardized-residuals-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{augmented_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(.std.resid }\OperatorTok{>}\StringTok{ }\DecValTok{2} \OperatorTok{|}\StringTok{ }\NormalTok{.std.resid }\OperatorTok{<}\StringTok{ }\DecValTok{-2}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(obs_num, .std.resid)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   obs_num .std.resid
##     <int>      <dbl>
## 1       6       7.87
## 2      78       2.28
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_std_resid <-}\StringTok{ }\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{obs_num =} \KeywordTok{row_number}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{6} \OperatorTok{|}\StringTok{ }\NormalTok{obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{78}\NormalTok{)}

\NormalTok{nba_std_resid }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(obs_num, PLAYER_NAME)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   obs_num PLAYER_NAME    
##     <int> <chr>          
## 1       6 LeBron James   
## 2      78 Carmelo Anthony
\end{verbatim}

The players with standardized residuals of magnitude greater than 2 are
LeBron James and Carmelo Anthony--two players who are also classified as
high leverage points. By definition, LeBron and Carmelo are outliers;
however, it remains to be seen whether Carmelo impacts the regression
line (we already examined LeBron's effect).

To assess the impact of prominent athletes (identified by high leverage
and/or high standardized residuals) on the regression line, we examine
Cook's Distance:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ augmented_data, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ obs_num, }\DataTypeTok{y =}\NormalTok{ .cooksd)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{1}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Observation Number"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Cook's Distance"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Cook's Distance"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_text}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =} \KeywordTok{ifelse}\NormalTok{(.cooksd }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{, }\KeywordTok{as.character}\NormalTok{(obs_num), }\StringTok{""}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/Cooks-Distance-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_std_resid }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(obs_num }\OperatorTok{==}\StringTok{ }\DecValTok{6}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(obs_num, PLAYER_NAME)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 2
##   obs_num PLAYER_NAME 
##     <int> <chr>       
## 1       6 LeBron James
\end{verbatim}

It is clear from the plot of Cook's Distance vs.~observation number that
LeBron James is the only influential point.

Since our objective is to accurately predict the Twitter follower counts
of NBA players, it is probably best to exclude LeBron to avoid
overestimating for less prominent athletes. Hence, we will continue our
analysis by using the multiple linear regression model without LeBron
James (\texttt{m\_final\_noLJ}).

To conclude, we will display the final model once more:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(m_final_noLJ, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & 1.087 & 0.229 & 4.742 & 0.000 & 0.632 &
1.543\tabularnewline
salary\_millionsCent & 0.109 & 0.027 & 4.035 & 0.000 & 0.055 &
0.162\tabularnewline
w\_pctCent & 4.609 & 1.568 & 2.940 & 0.004 & 1.495 &
7.724\tabularnewline
salary\_millionsCent:w\_pctCent & 0.431 & 0.171 & 2.513 & 0.014 & 0.090
& 0.771\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{discussion-of-assumptions}{%
\subsubsection{Discussion of
Assumptions}\label{discussion-of-assumptions}}

According to our dataset, 5 observations have players who are missing
Twitter handles. These values are missing at random because missingness
depends on other observed variables (like the person's social media
usage, etc.). The probability that a variable is missing depends on
information not included in our dataset. We decided to remove the 5
players from our dataset because there were very few observations with
missing values, and after removing these variables, we still had 95
observations. The observations with missingness are also random, so the
resulting analysis will not be biased because the missingness does not
differ systematically from the complete observations. In addition, since
our objective is predicting the number of Twitter followers for NBA
athletes, players without Twitter accounts are outside of the model's
predictive capabilities and hence do not belong in the dataset.

One other modification we have made to our original dataset is removing
LeBron James. We decided, based on Cook's distance, standardized
residuals, and leverage, LeBron was an influential point with a
significant effect on the regression line. Consequently, we removed
LeBron to avoid overestimation in our model. Because we removed LeBron,
we will use standardized residuals from here on out

Therefore, we are left with 94 observations, which is still a large
enough sample population to build a model which can be generalized to a
larger population of NBA athletes.

Next, we will check the linearity, constant variance, normality, and
independence assumptions to see if inference and predictions will be
reliable.

First, we will check for linearity and whether the response variable has
a linear relationship with the predictor variables in the model. We will
check the plot of standardized residuals vs.~predicted values:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m_final_aug <-}\StringTok{ }\KeywordTok{augment}\NormalTok{(m_final_noLJ)}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m_final_aug, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ .fitted, }\DataTypeTok{y =}\NormalTok{ .std.resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Predicted"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Standardized Residuals"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Standardized Residuals vs. Predicted"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-15-1.pdf}

When observing for constant variance, the height of the cloud of points
seems to increase as you move from left to right. Points are clustered
at the very left then grow to be more spare as you move along the graph.
Therefore, constant variance is not satisfied.

There is no obvious pattern and the shape of the graph seems to be
linear. Hence, this plot presents no issues with the linearity
assumption.

Next, we will observe the plot of residuals vs.~predictors:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m_final_aug, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ salary_millionsCent, }\DataTypeTok{y =}\NormalTok{ .std.resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Salary (Millions)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Standardized Residuals"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Standardized Residuals vs. Salary (Millions)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-16-1.pdf}

There looks to be a pattern in the plot because towards the end it
curves upward drastically. Therefore, this pattern suggests that
interactions or higher-order terms (like quadratic terms) are required.
Thus, linearity is not satisfied.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m_final_aug, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ w_pctCent, }\DataTypeTok{y =}\NormalTok{ .std.resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Percentage of Games Played Won"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Standardized Residuals"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Standardized Residuals vs. Percentage of Games Played Won"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-17-1.pdf}

There looks to be a pattern in the plot because towards the end it also
curves upward drastically. Therefore, this pattern suggests that
interactions or higher-order terms (like quadratic terms) are required.
Linearity is not satisfied.

Next, we will check for the normality assumption by creating a histogram
of the residuals and a normal QQ-plot of the residuals.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod2 <-}\StringTok{ }\NormalTok{nba_social_power_mod2 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{predicted =} \KeywordTok{predict.lm}\NormalTok{(m_final_noLJ), }\DataTypeTok{std_resid =} \KeywordTok{rstandard}\NormalTok{(m_final_noLJ))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod2, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ std_resid)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_histogram}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Distribution of Standardized Residuals"}\NormalTok{, }\DataTypeTok{x =} \StringTok{"Standardized Residuals"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-19-1.pdf}

Normality is violated because the histogram of residuals is heavily
right skewed because the height of the graphs decreases dramatically
from right to left.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod2, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =}\NormalTok{ std_resid)) }\OperatorTok{+}\StringTok{ }\KeywordTok{stat_qq}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{stat_qq_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"QQ Plot"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-20-1.pdf}

However, normality is not satisfied because some of the points don't
follow the diagonal line.

Lastly, we will check for independence. Data was not taken over time, so
we know there is no temporal correlation. There is also no spatial
correlation because data was not taken in space. We can check to see if
there is some structure/order to the dataset according to observation
number. There is no purposeful order to how the dataset was collected
according to Kaggle, but we will check just in case:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m_final_aug <-}\StringTok{ }\NormalTok{m_final_aug }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{obs_num =} \DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(m_final_aug))}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m_final_aug, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ obs_num, }\DataTypeTok{y =}\NormalTok{ .std.resid)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Observation Number"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Residuals"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Residuals vs. Observation Number"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-21-1.pdf}

Looking at the graph, there is no distinguishable pattern in the graph.
The number of Twitter followers of one player will not affect the number
of Twitter followers of another player. Therefore, independence is
satisfied.

Therefore, because constant variance and normality and linearity are not
satisfied, but independence is, we will make some adjustments to our
model. We can adjust for linearity by adding squared terms for salary
and percentage of games played won because those standardized residuals
vs.~predictor variable plots violated linearity. For constant variance,
we can log-transform the response variable because our standardized
residuals vs.~predicted values violated constant variance. Lastly, for
normality regression there were outliers observed in the histograms, so
we can try to remove all 7 outlier players from our model as mentioned
previously above because Kevin Durant, LeBron James, Josh Huestis,
JaVale McGee, David West, Jarnell Stokes, and Carmelo Anthony are
considered high leverage players (and hence potential influential
points).

After making these adjustments our model looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod3 <-}\StringTok{ }\NormalTok{nba_social_power_mod2 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{TWITTER_FOLLOWER_COUNT_MILLIONS_LOG =} \KeywordTok{log}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(PLAYER_NAME }\OperatorTok{!=}\StringTok{ "Kevin Durant"} \OperatorTok{&}\StringTok{ }\NormalTok{PLAYER_NAME }\OperatorTok{!=}\StringTok{ "Josh Huestis"} \OperatorTok{&}\StringTok{ }\NormalTok{PLAYER_NAME }\OperatorTok{!=}\StringTok{ "JaVale McGee"} \OperatorTok{&}\StringTok{ }\NormalTok{PLAYER_NAME }\OperatorTok{!=}\StringTok{ "David West"} \OperatorTok{&}\StringTok{ }\NormalTok{PLAYER_NAME }\OperatorTok{!=}\StringTok{ "Jarnell Stokes"} \OperatorTok{&}\StringTok{ }\NormalTok{PLAYER_NAME }\OperatorTok{!=}\StringTok{ "Carmelo Anthony"}\NormalTok{)}

\NormalTok{m_final_adjust <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS_LOG }\OperatorTok{~}\StringTok{ }\NormalTok{salary_millionsCent }
                     \OperatorTok{+}\StringTok{ }\KeywordTok{I}\NormalTok{(salary_millionsCent }\OperatorTok{*}\StringTok{ }\NormalTok{salary_millionsCent)}
                     \OperatorTok{+}\StringTok{ }\NormalTok{w_pctCent }
                 \OperatorTok{+}\StringTok{ }\KeywordTok{I}\NormalTok{(w_pctCent }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent)}
                 \OperatorTok{+}\StringTok{ }\NormalTok{salary_millionsCent }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent,}
               \DataTypeTok{data =}\NormalTok{ nba_social_power_mod3)}

\KeywordTok{tidy}\NormalTok{(m_final_adjust, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
\begin{minipage}[b]{0.36\columnwidth}\raggedright
term\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedleft
estimate\strut
\end{minipage} & \begin{minipage}[b]{0.08\columnwidth}\raggedleft
std.error\strut
\end{minipage} & \begin{minipage}[b]{0.08\columnwidth}\raggedleft
statistic\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\raggedleft
p.value\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedleft
conf.low\strut
\end{minipage} & \begin{minipage}[b]{0.08\columnwidth}\raggedleft
conf.high\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.36\columnwidth}\raggedright
(Intercept)\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
-1.169\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.279\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
-4.188\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.000\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
-1.725\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
-0.614\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
salary\_millionsCent\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.148\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.020\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
7.532\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.000\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.109\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.187\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
I(salary\_millionsCent * salary\_millionsCent)\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
-0.004\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.003\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
-1.592\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.115\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
-0.010\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.001\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
w\_pctCent\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
2.081\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
1.218\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
1.708\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.091\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
-0.342\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
4.505\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
I(w\_pctCent * w\_pctCent)\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
6.565\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
7.571\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.867\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.388\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
-8.496\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
21.625\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
salary\_millionsCent:w\_pctCent\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
-0.109\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.173\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
-0.629\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.531\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
-0.454\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.236\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

However, because the interaction effect and w\_pctCent squared terms and
the salary\_millionsCent have p-values that are very large and
\textgreater{} 0.05, we will remove them from our model to produce this
model. We will attempt to see if the log transformation of our response
variable is enough to support our assumptions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m_final_adjust <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS_LOG }\OperatorTok{~}\StringTok{ }\NormalTok{salary_millionsCent }
                     \OperatorTok{+}\StringTok{ }\NormalTok{w_pctCent,}
               \DataTypeTok{data =}\NormalTok{ nba_social_power_mod3)}

\KeywordTok{tidy}\NormalTok{(m_final_adjust, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & -1.398 & 0.149 & -9.370 & 0.000 & -1.694 &
-1.101\tabularnewline
salary\_millionsCent & 0.133 & 0.018 & 7.250 & 0.000 & 0.097 &
0.170\tabularnewline
w\_pctCent & 2.336 & 1.152 & 2.029 & 0.046 & 0.047 &
4.626\tabularnewline
\bottomrule
\end{longtable}

We will check for all assumptions again:

First, we will check for linearity and whether the response variable has
a linear relationship with the predictor variables in the model. We will
check the plot of standardized residuals vs.~predicted values:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m_final_adj_aug <-}\StringTok{ }\KeywordTok{augment}\NormalTok{(m_final_adjust)}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m_final_adj_aug, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ .fitted, }\DataTypeTok{y =}\NormalTok{ .std.resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Predicted"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Standardized Residuals"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Standardized Residuals vs. Predicted"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-24-1.pdf}

When observing for constant variance, the height of the cloud of points
seems to be constant as you move from left to right. Therefore, constant
variance is satisfied.

There is no obvious pattern and the shape of the graph seems to be
linear. Hence, this plot presents no issues with the linearity
assumption.

Next, we will observe the plot of residuals vs.~predictors:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m_final_adj_aug, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ salary_millionsCent, }\DataTypeTok{y =}\NormalTok{ .std.resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Salary (Millions)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Standardized Residuals"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Standardized Residuals vs. Salary (Millions)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-25-1.pdf}

There is no distinguishable pattern in our plot because there are no
discernible curves. Therefore, we satisfy linearity.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m_final_adj_aug, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ w_pctCent, }\DataTypeTok{y =}\NormalTok{ .std.resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Percentage of Games Played Won"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Standardized Residuals"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Standardized Residuals vs. Percentage of Games Played Won"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-26-1.pdf}

There looks to be no distinguishable pattern in the plot as well, so
therefore linearity is supported because there have been previous
violations of linearity.

Next, we will check for the normality assumption by creating a histogram
of the residuals and a normal QQ-plot of the residuals.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod3 <-}\StringTok{ }\NormalTok{nba_social_power_mod3 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{predicted =} \KeywordTok{predict.lm}\NormalTok{(m_final_adjust), }\DataTypeTok{std_resid =} \KeywordTok{rstandard}\NormalTok{(m_final_adjust))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod3, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ std_resid)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_histogram}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Distribution of Standardized Residuals"}\NormalTok{,}
                                                                                         \DataTypeTok{x =} \StringTok{"Standardized Residuals"}\NormalTok{,}
                                                                                         \DataTypeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-28-1.pdf}

Normality is not supported because the histogram of residuals is not
normal and is now slightly left skewed because the height increases as
you move across the graph, then drastically decreases, but the
distribution is unimodal.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod2, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =}\NormalTok{ std_resid)) }\OperatorTok{+}\StringTok{ }\KeywordTok{stat_qq}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{stat_qq_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"QQ Plot"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-29-1.pdf}

However, normality is not satisfied because some of the points don't
follow the diagonal line.

Lastly, we will check for independence. Data was not taken over time, so
we know there is no temporal correlation. There is also no spatial
correlation because data was not taken in space. We can check to see if
there is some structure/order to the dataset according to observation
number. There is no purposeful order the data was collected in according
to Kaggle, but we will check just in case:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m_final_adj_aug <-}\StringTok{ }\NormalTok{m_final_adj_aug }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{obs_num =} \DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(m_final_adj_aug))}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m_final_aug, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ obs_num, }\DataTypeTok{y =}\NormalTok{ .std.resid)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Observation Number"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Standardized Residuals"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Standardized Residuals vs. Observation Number"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-30-1.pdf}

Looking at the graph, there is no distinguishable pattern in the graph.
The number of Twitter followers of one player will not affect the number
of Twitter followers of another player. Therefore, independence is
satisfied.

Linearity, constant variance, and normality are all satisfied in this
model. We have done everything we can to the best of our knowledge to
fix normality, so we will continue on with this model for
interpretations. Our final model output is:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(m_final_adjust, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & -1.398 & 0.149 & -9.370 & 0.000 & -1.694 &
-1.101\tabularnewline
salary\_millionsCent & 0.133 & 0.018 & 7.250 & 0.000 & 0.097 &
0.170\tabularnewline
w\_pctCent & 2.336 & 1.152 & 2.029 & 0.046 & 0.047 &
4.626\tabularnewline
\bottomrule
\end{longtable}

\texttt{TWITTER\_FOLLOWER\_COUNT\_MILLIONS\_LOG}-hat = -1.401 + 0.133 *
\texttt{salary\_millionsCent} + 2.442 * \texttt{pct\_Cent}

The p-values for each of these predictor variables are all \textless{}
0.05, so we know each of the predictor variables is a significant
predictor for our response variable.

Lastly, we will also check for multicollinearity in our model. If two or
more predictor variables are highly correlated in our model, our
regression may change eratically in response to small changes in our
data.

We will check the variance inflation factor (VIF) for every predictor
variable to check for concerns with multicollinearity:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(}\KeywordTok{vif}\NormalTok{(m_final_adjust))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: 'tidy.numeric' is deprecated.
## See help("Deprecated")
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 2
##   names                   x
##   <chr>               <dbl>
## 1 salary_millionsCent  1.09
## 2 w_pctCent            1.09
\end{verbatim}

None of the variables have VIFs greater than or equal to 10, so there
are no issues with multicollinearity.

\hypertarget{interpretations}{%
\subsubsection{Interpretations}\label{interpretations}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(m_final_adjust, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & -1.398 & 0.149 & -9.370 & 0.000 & -1.694 &
-1.101\tabularnewline
salary\_millionsCent & 0.133 & 0.018 & 7.250 & 0.000 & 0.097 &
0.170\tabularnewline
w\_pctCent & 2.336 & 1.152 & 2.029 & 0.046 & 0.047 &
4.626\tabularnewline
\bottomrule
\end{longtable}

Again, the final model is displayed above. Its equation is:
\texttt{log(TWITTER\_FOLLOWER\_COUNT\_MILLIONS)}-hat = -1.401 + 0.133 *
\texttt{salary\_millionsCent} + 2.442 * \texttt{w\_pctCent}.

The intercept of the model is -1.401, which means that a player with an
average salary of 4.2991926\times 10\^{}\{-16\} and win percentage of
4.9077053\times 10\^{}\{-17\} are expected to have exp(-1.401) million,
or approximately 246,350.490, Twitter followers.

The coefficient of \texttt{salary\_millionsCent} is 0.133, which means
that, for every 1 million increase in player salary, a player's Twitter
followers are expected to multiply by a factor of exp(0.133).

The coefficient of \texttt{w\_pctCent} is 2.442. This coefficient is
misleading, as an increase of 1 in win percent is only possible if a
team has 0 wins. So, this coefficient is better explained by every 0.1
increase in team win percentage, a player's Twitter followers are
expected to multiply by a factor of exp(0.2442).

Interpreting coefficients is not particularly important, however, as our
objective is to predict Twitter followers.

\hypertarget{predictions}{%
\subsubsection{Predictions}\label{predictions}}

We have carefully selected 3 players from the 2016-2017 season who are
not included in the dataset, and will test the model's predictive
accuracy by comparing predicted Twitter follower counts to actual
Twitter data from 2017.

Salary data was taken from ESPN
(\url{http://www.espn.com/nba/salaries/_/year/2017/page/1}), and win
percent data was calculated from team data via Nba.com
(\url{https://stats.nba.com/players/traditional/?sort=PTS\&dir=-1\&Season=2016-17\&SeasonType=Regular\%20Season}).
The number of Twitter followers was collected from various articles
written in 2017.

Derrick Rose:

\texttt{salary\_millionsCent} = 21.3 million \texttt{w\_pctCent} = 0.406

-1.401 + 0.133 * (21.3) + 2.442 * (0.406) = 2.423

Derrick Rose's Twitter followers are expected to be exp(2.423) = 11.28
million followers. He actually had 24.9 million Twitter followers, so
this is an extreme overprediction.

Wesley Matthews:

\texttt{salary\_millionsCent} = 17.1 million \texttt{w\_pctCent} = 0.397

-1.401 + 0.133 * (17.1) + 2.442 * (0.397) = 1.843

Wesley Matthews's Twitter followers are expected to be exp(1.843) =
6.314 million Twitter followers. He actually had 0.241 million Twitter
followers, another extreme overprediction. This can be attributed to his
high salary, however, so the model overpredicts for that reason.

Boris Diaw:

\texttt{salary\_millionsCent} = 12.3 million \texttt{w\_pctCent} = 0.848

-1.401 + 0.133 * (7) + 2.442 * (0.616) = 1.034

Boris Diaw's Twitter followers are expected to be exp(1.034) = 2.813
million followers. He actually had 0.462 million Twitter followers. This
time, his winning record made a significant impact in increasing this
prediction.

The model has poor preditive capacity. We would like some feedback about
how to improve this by possibly adding more significant terms.

It is important to note that the dates at which these Twitter follow
counts were recorded vary and do not perfectly coincide with the data
collection of this dataset. However, the dataset itself only specifies
that the data was collected during the 2016-2017 season, and these
articles came from during the season as well.

\hypertarget{complete-eda}{%
\subsubsection{Complete EDA:}\label{complete-eda}}

The plots that were included in the EDA in the main body of our analysis
are NOT included again here, only the ones that were created but we did
not decide to include above.

\hypertarget{univariate-1}{%
\paragraph{Univariate}\label{univariate-1}}

First, we will do univariate EDA on the dataset. Player name will be
used to refer to observations in our dataset, but since each player name
is distinct we do not need to do EDA on the \texttt{PLAYER\_NAME}
variable.

Here, we'll take a look at how many players there are from each team in
the dataset:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(TEAM_ABBREVIATION) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 30 x 2
##    TEAM_ABBREVIATION     n
##    <chr>             <int>
##  1 SAC                   1
##  2 CHI                   2
##  3 IND                   2
##  4 LAL                   2
##  5 MIA                   2
##  6 MIN                   2
##  7 ORL                   2
##  8 WAS                   2
##  9 ATL                   3
## 10 BKN                   3
## # ... with 20 more rows
\end{verbatim}

As we can see from the output, there is only one team that is
represented just once in the dataset: SAC, the Sacramento Kings. The
greatest number of times teams are represented in the dataset is 5. GSW
(Golden State Warriors), LAC (Los Angeles Clippers), and SAS (San
Antonio Spurs) are all represented 5 times.

Now, we'll explore the distribution of the \texttt{AGE} variable in the
dataset:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ AGE)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Age"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{, }\DataTypeTok{title =} \StringTok{"Distribution of Age"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-33-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(AGE), }\DataTypeTok{min=} \KeywordTok{min}\NormalTok{(AGE), }\DataTypeTok{Q1 =} \KeywordTok{quantile}\NormalTok{(AGE, }\FloatTok{.25}\NormalTok{), }\DataTypeTok{median =} \KeywordTok{median}\NormalTok{(AGE), }
            \DataTypeTok{Q3 =} \KeywordTok{quantile}\NormalTok{(AGE, }\FloatTok{.75}\NormalTok{),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(AGE))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
##    mean   min    Q1 median    Q3   max
##   <dbl> <dbl> <dbl>  <int> <dbl> <dbl>
## 1  27.4    20  24.5     27    29    39
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(AGE)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 26
##   PLAYER_NAME TEAM_ABBREVIATI~   AGE W_PCT OFF_RATING DEF_RATING NET_RATING
##   <chr>       <chr>            <int> <dbl>      <dbl>      <dbl>      <dbl>
## 1 Dirk Nowit~ DAL                 39 0.426       105.       106.       -1.7
## # ... with 19 more variables: AST_RATIO <dbl>, REB_PCT <dbl>,
## #   USG_PCT <dbl>, PIE <dbl>, SALARY_MILLIONS <dbl>,
## #   ACTIVE_TWITTER_LAST_YEAR <int>, TWITTER_FOLLOWER_COUNT_MILLIONS <dbl>,
## #   PTS <dbl>, ageCent <dbl>, ast_ratioCent <dbl>, off_ratingCent <dbl>,
## #   def_ratingCent <dbl>, net_ratingCent <dbl>, PIECent <dbl>,
## #   reb_pctCent <dbl>, usg_pctCent <dbl>, salary_millionsCent <dbl>,
## #   w_pctCent <dbl>, ptsCent <dbl>
\end{verbatim}

As we can see from the histogram, age is somewhat normally distributed
in the dataset, with a mode around 27 and a surprisingly low number of
30-year olds. The mean age, 27.39, and median age, 27, are very close
together, indicating little skew. The lowest age is 20 and the highest
is 39. The oldest player by far, at 39, is Dirk Nowitzki.

Now, we'll examine the distribution of win percent, \texttt{W\_PCT}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ W_PCT)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{.05}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Win Percent"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{, }\DataTypeTok{title =} \StringTok{"Distribution of Win Percent"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/plot-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(W_PCT), }\DataTypeTok{min=} \KeywordTok{min}\NormalTok{(W_PCT), }\DataTypeTok{Q1 =} \KeywordTok{quantile}\NormalTok{(W_PCT, }\FloatTok{.25}\NormalTok{),}
            \DataTypeTok{median =} \KeywordTok{median}\NormalTok{(W_PCT), }\DataTypeTok{Q3 =} \KeywordTok{quantile}\NormalTok{(W_PCT, }\FloatTok{.75}\NormalTok{),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(W_PCT))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
##    mean   min    Q1 median    Q3   max
##   <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1 0.511     0 0.418  0.507  0.63 0.824
\end{verbatim}

As we can see from the histogram, win percent is also somewhat normally
distributed, with a mode around 50 percent. The minimum win percent in
the dataset is 0, while the maximum is 82.4. The median of 50.7 is very
similar to the mean of 51\%. The fact that the mean and median win
percents in the dataset fall so close to 50\% indicate good randomness
in the dataset, b/c the mean and median win percents for all nba players
are 50\%.

Next, we'll look at the distributions for offensive rating,
\texttt{OFF\_RATING} and defensive rating \texttt{DEF\_RATING}, as well
as the distribution for \texttt{NET\_RATING}, which is the average of
the offensive and defensive rating:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ OFF_RATING)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Offensive Rating"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Offensive Rating"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-34-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{min=} \KeywordTok{min}\NormalTok{(OFF_RATING), }\DataTypeTok{median =} \KeywordTok{median}\NormalTok{(OFF_RATING),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(OFF_RATING))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##     min median   max
##   <dbl>  <dbl> <dbl>
## 1  86.8   108.  124.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ DEF_RATING)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Defensive Rating"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Defensive Rating"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-35-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{min=} \KeywordTok{min}\NormalTok{(DEF_RATING), }\DataTypeTok{median =} \KeywordTok{median}\NormalTok{(DEF_RATING),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(DEF_RATING))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##     min median   max
##   <dbl>  <dbl> <dbl>
## 1    93    106  118.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ NET_RATING)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Net Rating"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Net Rating"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-36-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{min=} \KeywordTok{min}\NormalTok{(NET_RATING), }\DataTypeTok{median =} \KeywordTok{median}\NormalTok{(NET_RATING),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(NET_RATING))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##     min median   max
##   <dbl>  <dbl> <dbl>
## 1 -17.2    1.5  18.7
\end{verbatim}

Defensive rating, offensive rating, and net rating do not stray far from
normally distributed. Offensive rating varies from 86.8 to 124.2, with a
median of 107.6. Defensive rating varies from 93 to 118.3, with a median
of 106. Thus, the dataset contains a larger range in terms of offensive
rating, and the median is also slightly higher for defensive rated
players. The distribution of net rating has multiple nearly equal modes
around -2 to -3 and around 1 and 3. The median net rating is 1.5, and
the net ratings in the dataset vary from -17.2 to 18.7.

Next, we'll look at the distribution of the assist-to-turnovers ratio,
\texttt{AST\_RATIO}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ AST_RATIO)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Assist-Turnover Ratio"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Assist-Turnover Ratio"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-37-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(AST_RATIO),}
            \DataTypeTok{min=} \KeywordTok{min}\NormalTok{(AST_RATIO),}
            \DataTypeTok{Q1 =} \KeywordTok{quantile}\NormalTok{(AST_RATIO, }\FloatTok{.25}\NormalTok{),}
            \DataTypeTok{median =} \KeywordTok{median}\NormalTok{(AST_RATIO),}
            \DataTypeTok{Q3 =} \KeywordTok{quantile}\NormalTok{(AST_RATIO, }\FloatTok{.75}\NormalTok{),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(AST_RATIO))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
##    mean   min    Q1 median    Q3   max
##   <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1  17.1     4  9.75     15  22.2  51.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(AST_RATIO)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 26
##   PLAYER_NAME TEAM_ABBREVIATI~   AGE W_PCT OFF_RATING DEF_RATING NET_RATING
##   <chr>       <chr>            <int> <dbl>      <dbl>      <dbl>      <dbl>
## 1 Jarnell St~ DEN                 23 0           115.       118.       -3.1
## 2 Ricky Rubio MIN                 26 0.373       109.       110.       -1  
## # ... with 19 more variables: AST_RATIO <dbl>, REB_PCT <dbl>,
## #   USG_PCT <dbl>, PIE <dbl>, SALARY_MILLIONS <dbl>,
## #   ACTIVE_TWITTER_LAST_YEAR <int>, TWITTER_FOLLOWER_COUNT_MILLIONS <dbl>,
## #   PTS <dbl>, ageCent <dbl>, ast_ratioCent <dbl>, off_ratingCent <dbl>,
## #   def_ratingCent <dbl>, net_ratingCent <dbl>, PIECent <dbl>,
## #   reb_pctCent <dbl>, usg_pctCent <dbl>, salary_millionsCent <dbl>,
## #   w_pctCent <dbl>, ptsCent <dbl>
\end{verbatim}

As we can see from the histogram, the assist-turnover ratio is very
right skewed. The mode is at around 10, even though the median is at 15,
and the mean is 17.12526, all of which are summary statistics that
emphasize the right skew. This means that while most players in the
dataset had a very high assist-turnover ratio (meaning they had many
more assists than turnovers), there is a wider variation among players
with a high ratio and the players with lower ratios are concentrated
around a few numbers. The dataset minimum ratio of 4 means that there
were no players with more turnovers than assists. Notably, this is the
first variable we've examined so far with a significantly non-normal
distribution. The two players with very high assist-turnover ratios,
51.5 and 41.3, are Jarnell Stokes and Ricky Rubio, respectively.

Next, we'll examine the variation of \texttt{REB\_PCT}, the percent of
rebounds a player makes:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ REB_PCT)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{.01}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Rebound Percentage"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Rebound Percentage"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-38-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(REB_PCT),}
            \DataTypeTok{min=} \KeywordTok{min}\NormalTok{(REB_PCT),}
            \DataTypeTok{Q1 =} \KeywordTok{quantile}\NormalTok{(REB_PCT, }\FloatTok{.25}\NormalTok{),}
            \DataTypeTok{median =} \KeywordTok{median}\NormalTok{(REB_PCT),}
            \DataTypeTok{Q3 =} \KeywordTok{quantile}\NormalTok{(REB_PCT, }\FloatTok{.75}\NormalTok{),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(REB_PCT))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
##    mean   min     Q1 median    Q3   max
##   <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl>
## 1 0.133 0.045 0.0825  0.127 0.180 0.252
\end{verbatim}

The distribution of rebound percentage has a minimum of 0.045 and a
maximum of 0.252. The distribution is not very skewed one way or
another, as supported by the similar mean of .133 and median of .127.
However, the distribution is not normal in that it does not resemble a
bell curve; with exceptions, the data is somewhat evenly distributed
from the minimum to near the maximum (although there is some trail-off
towards the right side of the distribution). This non-normal spread is
likely partially an indication of the fact that the dataset contains
both offensive and defensive players, because whether a player is on
offense or defense has a significant effect on their rebound percentage.

Next, we'll look at \texttt{USG\_PCT}, usage percentage, which is an
estimate of how often a player makes team plays:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ USG_PCT)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{.01}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Usage Percentage"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Usage Percentage"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-39-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(USG_PCT),}
            \DataTypeTok{min=} \KeywordTok{min}\NormalTok{(USG_PCT),}
            \DataTypeTok{Q1 =} \KeywordTok{quantile}\NormalTok{(USG_PCT, }\FloatTok{.25}\NormalTok{),}
            \DataTypeTok{median =} \KeywordTok{median}\NormalTok{(USG_PCT),}
            \DataTypeTok{Q3 =} \KeywordTok{quantile}\NormalTok{(USG_PCT, }\FloatTok{.75}\NormalTok{),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(USG_PCT))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
##    mean   min    Q1 median    Q3   max
##   <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1 0.238 0.101   0.2  0.242 0.276 0.408
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(USG_PCT)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 26
##   PLAYER_NAME TEAM_ABBREVIATI~   AGE W_PCT OFF_RATING DEF_RATING NET_RATING
##   <chr>       <chr>            <int> <dbl>      <dbl>      <dbl>      <dbl>
## 1 Russell We~ OKC                 28 0.568       108.       105.        3.3
## # ... with 19 more variables: AST_RATIO <dbl>, REB_PCT <dbl>,
## #   USG_PCT <dbl>, PIE <dbl>, SALARY_MILLIONS <dbl>,
## #   ACTIVE_TWITTER_LAST_YEAR <int>, TWITTER_FOLLOWER_COUNT_MILLIONS <dbl>,
## #   PTS <dbl>, ageCent <dbl>, ast_ratioCent <dbl>, off_ratingCent <dbl>,
## #   def_ratingCent <dbl>, net_ratingCent <dbl>, PIECent <dbl>,
## #   reb_pctCent <dbl>, usg_pctCent <dbl>, salary_millionsCent <dbl>,
## #   w_pctCent <dbl>, ptsCent <dbl>
\end{verbatim}

The distribution of usage percentage, with a minimum of .101 and a
maximum of .408, is fairly normally distributed. The mean, .238, and
median, .242, are similar. The fairly wide spread may indicate that the
dataset contains a decent sampling of players- some `star player' types
and others that are not the centerpieces of their teams.The maximum of
.408, while perhaps not quite an outlier, is separated from most of the
other points; this usage percentage belongs to Russell Westbrook.

Next, we'll examine \texttt{PIE}, player impact factor, a statistic
roughly measuring a player's impact on the games that they play that's
used by nba.com:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ PIE)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{.01}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Player Impact Factor"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Player Impact Factor Distribution"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-40-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(PIE),}
            \DataTypeTok{min=} \KeywordTok{min}\NormalTok{(PIE),}
            \DataTypeTok{Q1 =} \KeywordTok{quantile}\NormalTok{(PIE, }\FloatTok{.25}\NormalTok{),}
            \DataTypeTok{median =} \KeywordTok{median}\NormalTok{(PIE),}
            \DataTypeTok{Q3 =} \KeywordTok{quantile}\NormalTok{(PIE, }\FloatTok{.75}\NormalTok{),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(PIE))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
##    mean   min    Q1 median    Q3   max
##   <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1 0.139 0.112 0.122  0.131 0.152  0.23
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(PIE)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(PLAYER_NAME, PIE) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##    PLAYER_NAME             PIE
##    <chr>                 <dbl>
##  1 Russell Westbrook     0.23 
##  2 Demetrius Jackson     0.194
##  3 Anthony Davis         0.192
##  4 James Harden          0.19 
##  5 Kevin Durant          0.186
##  6 LeBron James          0.183
##  7 Chris Paul            0.182
##  8 DeMarcus Cousins      0.178
##  9 Giannis Antetokounmpo 0.176
## 10 Kawhi Leonard         0.174
\end{verbatim}

As we can see from the histogram, the player impact factor, with a
minimum of .112 and a maximum of .23, is quite right-skewed. The median
player impact factor is .131, and the mean is .139, evidence of the
right skew. The mode is around the median. The maximum, .23, is a
significant outlier, and is that of Russell Westbrook, the same player
who had by far the highest usage percentage; clearly, his data will need
to be examined more closely later to see if it ultimately affects our
model.

Next, we'll look at average points scored per game:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ nba_social_power_mod, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ PTS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{2}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Average Points Scored Per Game"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Average Points Scored Per Game"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-41-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(PTS),}
            \DataTypeTok{min=} \KeywordTok{min}\NormalTok{(PTS),}
            \DataTypeTok{Q1 =} \KeywordTok{quantile}\NormalTok{(PTS, }\FloatTok{.25}\NormalTok{),}
            \DataTypeTok{median =} \KeywordTok{median}\NormalTok{(PTS),}
            \DataTypeTok{Q3 =} \KeywordTok{quantile}\NormalTok{(PTS, }\FloatTok{.75}\NormalTok{),}
            \DataTypeTok{max =} \KeywordTok{max}\NormalTok{(PTS))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 6
##    mean   min    Q1 median    Q3   max
##   <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1  15.3   1.5   9.5   14.6  21.4  31.6
\end{verbatim}

As we can see from the histogram, the distribution of average points
scored is slightly normal, with some obvious departures from normality.
The median number of points scored per game is 14.6, and the mean is
15.28232. The maximum is 31.6, but this does not seem to be an obvious
outlier.

Next, we'll examine the variable \texttt{ACTIVE\_TWITTER\_LAST\_YEAR},
which tells us whether or not each player posted on Twitter the year
before the data was collected:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nba_social_power_mod <-}\StringTok{ }\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{ACTIVE_TWITTER_LAST_YEAR =} \KeywordTok{as.factor}\NormalTok{(ACTIVE_TWITTER_LAST_YEAR))}

\NormalTok{nba_social_power_mod }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(ACTIVE_TWITTER_LAST_YEAR)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   ACTIVE_TWITTER_LAST_YEAR     n
##   <fct>                    <int>
## 1 0                            2
## 2 1                           93
\end{verbatim}

Out of the 95 players in our modified dataset, 2 were not active on
Twitter the year before the data was collected and and 93 were.

\hypertarget{bivariate-1}{%
\paragraph{Bivariate}\label{bivariate-1}}

Next, we will do bivariate EDA, looking into the relationships of some
of the predictor variables with the response variables. We won't do
bivariate EDA on player name, Twitter handle, age, team abbreviation, or
whether the players were active on Twitter last year, instead focusing
on terms we believe may play a more nuanced / important role in
predicting Twitter followers.

Here, we'll look at the relationship between assist-to-turnovers ratio
and Twitter follower count:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(nba_social_power_mod, }
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ AST_RATIO,}
           \DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Relationship Between Assist-Turnover Ratio and Twitter Follower Count"}\NormalTok{, }
       \DataTypeTok{x =} \StringTok{"Assist-Turnover Ratio"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-43-1.pdf}

There is no evident relationship between assist-turnover ratio and
Twitter follower count.

Next, we'll examine whether there is a relationship between rebound
percentage and Twitter follower count:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(nba_social_power_mod, }
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ REB_PCT,}
           \DataTypeTok{y =}\NormalTok{ TWITTER_FOLLOWER_COUNT_MILLIONS)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Relationship Between Rebound Percentage and Twitter Follower Count"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Rebound Percentage"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Twitter Follower Count, in Millions"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-44-1.pdf}

There is no evident relationship between rebound percentage and Twitter
follower count.

There may have been some slight linearity issues with our current model.
Though there is not a discernible pattern in our residuals plot for
salary, there was slight curvature, so we were interested to see if we
could fix this with a log-transformation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m_final_add <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(TWITTER_FOLLOWER_COUNT_MILLIONS_LOG }\OperatorTok{~}\StringTok{ }\KeywordTok{log}\NormalTok{(salary_millionsCent) }
                     \OperatorTok{+}\StringTok{ }\NormalTok{w_pctCent }
                  \OperatorTok{+}\StringTok{ }\KeywordTok{log}\NormalTok{(salary_millionsCent) }\OperatorTok{*}\StringTok{ }\NormalTok{w_pctCent,}
               \DataTypeTok{data =}\NormalTok{ nba_social_power_mod3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in log(salary_millionsCent): NaNs produced
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(m_final_add, }\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{(}\DataTypeTok{format =} \StringTok{"markdown"}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
term & estimate & std.error & statistic & p.value & conf.low &
conf.high\tabularnewline
\midrule
\endhead
(Intercept) & -0.621 & 0.431 & -1.441 & 0.157 & -1.492 &
0.250\tabularnewline
log(salary\_millionsCent) & 0.165 & 0.224 & 0.736 & 0.466 & -0.288 &
0.618\tabularnewline
w\_pctCent & 4.088 & 2.759 & 1.482 & 0.146 & -1.489 &
9.665\tabularnewline
log(salary\_millionsCent):w\_pctCent & -1.157 & 1.653 & -0.700 & 0.488 &
-4.497 & 2.183\tabularnewline
\bottomrule
\end{longtable}

Our p-values are extremely high for all coefficients, which means that
predicted variables are not significant predictors for the response
variable. Therefore, we will not continue with this model, because our
final model from before is significant and satisfies assumptions fairly
well.


\end{document}
